{
  "batch_mode": "complete_episodes",
  "callbacks": "<ray.rllib.algorithms.callbacks.MultiCallbacks object at 0x7fbe5b753640>",
  "clip_param": 0.2,
  "entropy_coeff": 0,
  "env": "transport",
  "env_config": {
    "continuous_actions": true,
    "device": "cpu",
    "max_steps": 100,
    "num_envs": 60,
    "scenario_config": {
      "collision_reward": -0.1,
      "dist_shaping_factor": 1,
      "n_agents": 4,
      "n_obstacles": 0
    },
    "scenario_name": "transport"
  },
  "evaluation_config": {
    "callbacks": "<ray.rllib.algorithms.callbacks.MultiCallbacks object at 0x7fbe5b7535e0>",
    "env_config": {
      "num_envs": 1
    },
    "num_envs_per_worker": 1
  },
  "evaluation_duration": 1,
  "evaluation_interval": 30,
  "evaluation_num_workers": 1,
  "evaluation_parallel_to_training": false,
  "framework": "torch",
  "gamma": 0.99,
  "grad_clip": 40,
  "kl_coeff": 0,
  "kl_target": 0.01,
  "lambda": 0.9,
  "lr": 5e-05,
  "model": {
    "custom_action_dist": "hom_multi_action",
    "custom_model": "GPPO",
    "custom_model_config": {
      "activation_fn": "tanh",
      "add_agent_index": false,
      "aggr": "add",
      "centralised_critic": false,
      "gnn_type": "MatPosConv",
      "heterogeneous": true,
      "pos_dim": 2,
      "pos_start": 0,
      "share_action_value": true,
      "share_observations": true,
      "topology_type": "full",
      "trainer": "MultiPPOTrainer",
      "use_beta": false,
      "use_mlp": false,
      "vel_dim": 2,
      "vel_start": 2
    },
    "vf_share_layers": true
  },
  "num_envs_per_worker": 60,
  "num_gpus": 1,
  "num_gpus_per_worker": 0,
  "num_sgd_iter": 45,
  "num_workers": 6,
  "rollout_fragment_length": 166,
  "seed": 0,
  "sgd_minibatch_size": 4096,
  "train_batch_size": 60000,
  "use_critic": true,
  "use_gae": true,
  "vf_clip_param": Infinity,
  "vf_loss_coeff": 1
}